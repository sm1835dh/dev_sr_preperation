#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
PostgreSQL ìŠ¤í™ ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ - ê²€ì¦ ê·œì¹™ ê¸°ë°˜ (Validation Rule Based)
================================================================================

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê²€ì¦ ê·œì¹™ í…Œì´ë¸”(staging)ì„ ê¸°ë°˜ìœ¼ë¡œ PostgreSQL í…Œì´ë¸”ì˜ ìŠ¤í™ ë°ì´í„°ì—ì„œ
dimension (width, height, depth) ì •ë³´ë¥¼ íŒŒì‹±í•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤.

í…Œì´ë¸” êµ¬ì¡°:
-----------
1. kt_spec_validation_table_20251021_staging: ê²€ì¦ ê·œì¹™ í…Œì´ë¸”
   - is_target=trueì¸ ë ˆì½”ë“œë§Œ ì²˜ë¦¬
   - is_completed: íŒŒì‹± ì™„ë£Œ ì—¬ë¶€

2. kt_spec_validation_table_20251021: ì†ŒìŠ¤ ë°ì´í„° í…Œì´ë¸”
   - ì‹¤ì œ ìŠ¤í™ ë°ì´í„° í¬í•¨

3. kt_spec_validation_table_20251021_mod: íŒŒì‹± ê²°ê³¼ í…Œì´ë¸”
   - target_disp_nm2: ì‚¬ìš©ì ì •ì˜ ëª…ì¹­
   - dimension_type: ['depth', 'height', 'width'] í˜•ì‹ì˜ ë¦¬ìŠ¤íŠ¸
   - is_target, is_completed: ëª¨ë‘ trueë¡œ ì„¤ì •

ì‚¬ìš©ë²•:
------
1. ê¸°ë³¸ ì‹¤í–‰:
   python transform_spec.py

2. mod í…Œì´ë¸” ë°ì´í„° ìœ ì§€í•˜ë©° ì‹¤í–‰:
   python transform_spec.py --no-truncate

í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ (.env íŒŒì¼ì— ì„¤ì •):
--------------------------------
PG_HOST=localhost
PG_PORT=5432
PG_DATABASE=your_database
PG_USER=your_username
PG_PASSWORD=your_password

ì£¼ìš” ê¸°ëŠ¥:
---------
1. staging í…Œì´ë¸”ì—ì„œ is_target=trueì¸ ê²€ì¦ ê·œì¹™ ë¡œë“œ
2. ì†ŒìŠ¤ í…Œì´ë¸”ì—ì„œ ë§¤ì¹­ë˜ëŠ” ë°ì´í„° ì¡°íšŒ
3. ë‹¤ì–‘í•œ í˜•ì‹ì˜ dimension ë°ì´í„° íŒŒì‹±
4. mod í…Œì´ë¸”ì— íŒŒì‹± ê²°ê³¼ ì €ì¥
5. staging í…Œì´ë¸”ì˜ is_completed ì—…ë°ì´íŠ¸

================================================================================
"""

import os
import sys
import argparse
import re
import pandas as pd
from sqlalchemy import create_engine, text
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# í…Œì´ë¸” ì´ë¦„ ì •ì˜
STAGING_TABLE = 'kt_spec_validation_table_20251021_staging'
SOURCE_TABLE = 'kt_spec_validation_table_20251021'
MOD_TABLE = 'kt_spec_validation_table_20251021_mod'

def get_sqlalchemy_engine():
    """SQLAlchemy ì—”ì§„ ìƒì„±"""
    try:
        connection_string = f"postgresql://{os.getenv('PG_USER')}:{os.getenv('PG_PASSWORD')}@{os.getenv('PG_HOST')}:{os.getenv('PG_PORT')}/{os.getenv('PG_DATABASE')}"
        engine = create_engine(connection_string)
        print(f"âœ… SQLAlchemy ì—”ì§„ ìƒì„± ì„±ê³µ")
        return engine
    except Exception as e:
        print(f"âŒ SQLAlchemy ì—”ì§„ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

def load_validation_rules(engine):
    """
    staging í…Œì´ë¸”ì—ì„œ is_target=trueì¸ validation ê·œì¹™ ë¡œë“œ

    Parameters:
    - engine: SQLAlchemy engine

    Returns:
    - DataFrame with validation rules
    """
    try:
        query = f"""
        SELECT disp_lv1, disp_lv2, disp_lv3, disp_nm1, disp_nm2,
               target_disp_nm2, dimension_type, is_target, is_completed
        FROM {STAGING_TABLE}
        WHERE is_target = true AND (is_completed = false OR is_completed IS NULL)
        """
        df = pd.read_sql(query, engine)
        print(f"âœ… ê²€ì¦ ê·œì¹™ {len(df)}ê°œ ë¡œë“œ ì™„ë£Œ (is_target=true, is_completed=false)")
        return df
    except Exception as e:
        print(f"âŒ ê²€ì¦ ê·œì¹™ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def load_data_with_validation_rules(engine, validation_rules_df):
    """
    validation ê·œì¹™ì— ë§¤ì¹­ë˜ëŠ” ë°ì´í„°ë¥¼ ì†ŒìŠ¤ í…Œì´ë¸”ì—ì„œ ë¡œë“œ

    Parameters:
    - engine: SQLAlchemy engine
    - validation_rules_df: ê²€ì¦ ê·œì¹™ DataFrame

    Returns:
    - DataFrame with matched data and validation rules
    """
    try:
        all_data = []

        for _, rule in validation_rules_df.iterrows():
            # NULL ê°’ ì²˜ë¦¬
            conditions = []
            params = {}

            for idx, col in enumerate(['disp_lv1', 'disp_lv2', 'disp_lv3', 'disp_nm1', 'disp_nm2']):
                if pd.notna(rule[col]):
                    conditions.append(f"{col} = :param_{idx}")
                    params[f'param_{idx}'] = rule[col]
                else:
                    conditions.append(f"{col} IS NULL")

            where_clause = " AND ".join(conditions)
            query = text(f"SELECT * FROM {SOURCE_TABLE} WHERE {where_clause}")

            df_part = pd.read_sql(query, engine, params=params)

            # validation ê·œì¹™ ì •ë³´ ì¶”ê°€
            df_part['target_disp_nm2'] = rule['target_disp_nm2']
            df_part['validation_rule_id'] = f"{rule['disp_lv1']}|{rule['disp_lv2']}|{rule['disp_lv3']}|{rule['disp_nm1']}|{rule['disp_nm2']}"

            all_data.append(df_part)

        if all_data:
            df_combined = pd.concat(all_data, ignore_index=True)
            print(f"âœ… ê²€ì¦ ê·œì¹™ì— ë§¤ì¹­ë˜ëŠ” {len(df_combined)}ê°œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            return df_combined
        else:
            print("âš ï¸ ë§¤ì¹­ë˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None



def truncate_table(engine, table_name):
    """
    í…Œì´ë¸”ì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    
    Parameters:
    - engine: SQLAlchemy engine
    - table_name: í…Œì´ë¸”ëª…
    """
    try:
        with engine.connect() as conn:
            conn.execute(text(f"TRUNCATE TABLE {table_name} RESTART IDENTITY CASCADE"))
            conn.commit()
        print(f"âœ… í…Œì´ë¸” '{table_name}'ì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")
        return True
    except Exception as e:
        print(f"âŒ ë°ì´í„° ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False


# ============================================
# íŒŒì‹± í•¨ìˆ˜ ì •ì˜
# ============================================

def update_staging_table(engine, validation_rules_df, parsed_results, dimension_summaries):
    """
    staging í…Œì´ë¸”ì˜ is_completed ê°’ê³¼ dimension_type ì—…ë°ì´íŠ¸

    Parameters:
    - engine: SQLAlchemy engine
    - validation_rules_df: ì²˜ë¦¬í•œ ê²€ì¦ ê·œì¹™
    - parsed_results: íŒŒì‹± ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ {validation_rule_id: success}
    - dimension_summaries: {validation_rule_id: ['depth', 'width', ...]}
    """
    try:
        with engine.begin() as conn:
            for _, rule in validation_rules_df.iterrows():
                rule_id = f"{rule['disp_lv1']}|{rule['disp_lv2']}|{rule['disp_lv3']}|{rule['disp_nm1']}|{rule['disp_nm2']}"

                if rule_id in parsed_results and parsed_results[rule_id]:
                    # dimension_type ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    dimension_list = dimension_summaries.get(rule_id, [])
                    dimension_str = str(dimension_list) if dimension_list else None

                    # íŒŒì‹± ì„±ê³µí•œ ê²½ìš° is_completedì™€ dimension_type ì—…ë°ì´íŠ¸
                    conditions = []
                    params = {}

                    for idx, col in enumerate(['disp_lv1', 'disp_lv2', 'disp_lv3', 'disp_nm1', 'disp_nm2']):
                        if pd.notna(rule[col]):
                            conditions.append(f"{col} = :param_{idx}")
                            params[f'param_{idx}'] = rule[col]
                        else:
                            conditions.append(f"{col} IS NULL")

                    where_clause = " AND ".join(conditions)

                    if dimension_str:
                        params['dimension_type'] = dimension_str
                        update_query = text(f"""
                            UPDATE {STAGING_TABLE}
                            SET is_completed = true,
                                dimension_type = :dimension_type
                            WHERE {where_clause}
                        """)
                    else:
                        update_query = text(f"""
                            UPDATE {STAGING_TABLE}
                            SET is_completed = true
                            WHERE {where_clause}
                        """)

                    conn.execute(update_query, params)

        print(f"âœ… Staging í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì™„ë£Œ ({len([v for v in parsed_results.values() if v])}ê°œ ê·œì¹™ ì™„ë£Œ)")
        return True

    except Exception as e:
        print(f"âŒ Staging í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def save_to_mod_table(engine, df_parsed):
    """
    íŒŒì‹± ê²°ê³¼ë¥¼ mod í…Œì´ë¸”ì— ì €ì¥

    Parameters:
    - engine: SQLAlchemy engine
    - df_parsed: íŒŒì‹±ëœ ë°ì´í„° DataFrame
    """
    try:
        if len(df_parsed) == 0:
            print("âš ï¸ ì €ì¥í•  íŒŒì‹± ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return True

        # íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ì§ì ‘ ì €ì¥ (dimension_typeë³„ë¡œ row ìƒì„±)
        rows_to_insert = []

        for _, row in df_parsed.iterrows():
            row_dict = row.to_dict()

            # mod í…Œì´ë¸”ì— ì €ì¥í•  ë°ì´í„° ì¤€ë¹„
            insert_data = {
                'mdl_code': row_dict.get('mdl_code'),
                'goods_nm': row_dict.get('goods_nm'),
                'disp_lv1': row_dict.get('disp_lv1'),
                'disp_lv2': row_dict.get('disp_lv2'),
                'disp_lv3': row_dict.get('disp_lv3'),
                'category_lv1': row_dict.get('category_lv1'),
                'category_lv2': row_dict.get('category_lv2'),
                'category_lv3': row_dict.get('category_lv3'),
                'disp_nm1': row_dict.get('disp_nm1'),
                'disp_nm2': row_dict.get('disp_nm2'),
                'value': row_dict.get('value'),
                'is_numeric': row_dict.get('is_numeric'),
                'symbols': row_dict.get('symbols'),
                'new_value': row_dict.get('new_value'),
                'target_disp_nm2': row_dict.get('target_disp_nm2'),
                'dimension_type': row_dict.get('dimension_type'),  # ê°œë³„ dimension type (width, height, depth)
                'parsed_value': row_dict.get('parsed_value'),
                'needs_check': row_dict.get('needs_check', False)
            }
            rows_to_insert.append(insert_data)

        # DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í•œë²ˆì— ì €ì¥
        df_to_save = pd.DataFrame(rows_to_insert)

        # í…Œì´ë¸”ì— ì €ì¥
        df_to_save.to_sql(MOD_TABLE, engine, if_exists='append', index=False)

        # validation_rule_idë³„ë¡œ dimension_type ì§‘ê³„ (ì‚¬ìš©ì í™•ì¸ìš©)
        rule_summary = df_parsed.groupby('validation_rule_id')['dimension_type'].apply(
            lambda x: sorted(list(set(x)))
        )

        print(f"âœ… Mod í…Œì´ë¸”ì— {len(df_to_save)}ê°œ dimension ê°’ ì €ì¥ ì™„ë£Œ")
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ê·œì¹™ë³„ dimension íƒ€ì…:")
        for rule_id, dimensions in rule_summary.items():
            print(f"   - {dimensions}")

        return True

    except Exception as e:
        print(f"âŒ Mod í…Œì´ë¸” ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def identify_dimension_type(text):
    """
    í…ìŠ¤íŠ¸ì—ì„œ dimension íƒ€ì…ì„ ì‹ë³„

    Parameters:
    -----------
    text : str
        ë¶„ì„í•  í…ìŠ¤íŠ¸ (disp_nm2)
    """
    text_lower = text.lower()

    # L(Length) í‚¤ì›Œë“œ - depthë¡œ ë§¤í•‘
    if any(keyword in text_lower for keyword in ['ê¸¸ì´', 'l', 'length']):
        return 'depth'
    # Depth í‚¤ì›Œë“œ
    elif any(keyword in text_lower for keyword in ['ë‘ê»˜', 'ê¹Šì´', 'd']):
        return 'depth'
    # Width í‚¤ì›Œë“œ
    elif any(keyword in text_lower for keyword in ['ë„ˆë¹„', 'ê°€ë¡œ', 'í­', 'w']):
        return 'width'
    # Height í‚¤ì›Œë“œ
    elif any(keyword in text_lower for keyword in ['ì„¸ë¡œ', 'ë†’ì´', 'h']):
        return 'height'

    return None

def parse_dimensions_advanced(row):
    """
    dimension íŒŒì‹± í•¨ìˆ˜

    validation_ruleì— ë”°ë¼ ë°ì´í„°ë¥¼ íŒŒì‹±
    (í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ì²´í¬ ì œê±° - staging í…Œì´ë¸”ì˜ is_targetìœ¼ë¡œ ëŒ€ì²´)
    """
    parsed_rows = []
    value = str(row['value'])
    disp_nm2 = str(row.get('disp_nm2', ''))

    # ============================================
    # ì „ì²˜ë¦¬: ì œì™¸ ì¡°ê±´ ì²´í¬ ë° ê°’ ì¶”ì¶œ
    # ============================================
    # ì œì™¸ ì¡°ê±´: ê°ë„ ì¡°ì • ê´€ë ¨ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ê²½ìš°
    if any(keyword in value.lower() for keyword in ['ê°ë„ ì¡°ì •', 'ê°ë„ì¡°ì •']):
        return parsed_rows, False, False

    # ë³µìˆ˜ ê°œì˜ ê°’ì´ ìˆëŠ” ê²½ìš° ì²« ë²ˆì§¸ ê°’ë§Œ ì¶”ì¶œ
    # ì˜ˆ: "TOP/BOTTOM : 1460.0(L) x 24.6(W) x 17.7(H), LEFT/RIGHT : 837.4(L) x 24.6(W) x 17.7(H) mm"
    # â†’ "TOP/BOTTOM : 1460.0(L) x 24.6(W) x 17.7(H)"
    if ':' in value and ',' in value:
        # ì½œë¡ ê³¼ ì½¤ë§ˆê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ê·¸ë£¹ë§Œ ì¶”ì¶œ
        first_part = value.split(',')[0].strip()
        # "TOP/BOTTOM : ê°’" í˜•íƒœì—ì„œ ê°’ ë¶€ë¶„ë§Œ ì¶”ì¶œ
        if ':' in first_part:
            value = first_part.split(':', 1)[1].strip()
        else:
            value = first_part

    # í‚¤ë³´ë“œ ì„¸íŠ¸ì˜ ê²½ìš° ì²« ë²ˆì§¸ ì œí’ˆë§Œ íŒŒì‹±
    if 'í‚¤ë³´ë“œ' in value and ':' in value:
        keyboard_match = re.search(r'í‚¤ë³´ë“œ\s*:\s*([^ê°€-í£]*?)(?:ë§ˆìš°ìŠ¤|ë¦¬ì‹œë²„|$)', value)
        if keyboard_match:
            value = keyboard_match.group(1).strip()

    # íŒ¨í„´ 0: Wìˆ«ì x Dìˆ«ì x Hìˆ«ì í˜•ì‹ (ì˜ˆ: "W269 x D375 x H269 mm") + L ë§¤í•‘ ì§€ì›
    wdh_pattern = r'([WwHhDdLl])\s*([0-9,]+(?:\.[0-9]+)?)'
    wdh_matches = re.findall(wdh_pattern, value)

    if len(wdh_matches) >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ dimensionì´ ìˆëŠ” ê²½ìš°
        base_row = row.to_dict()
        dimension_map = {'w': 'width', 'h': 'height', 'd': 'depth', 'l': 'depth'}  # Lì„ depthë¡œ ë§¤í•‘

        for dim_letter, num_val in wdh_matches:
            dim_type = dimension_map.get(dim_letter.lower())
            if dim_type:
                # ì½¤ë§ˆ ì œê±° í›„ ìˆ«ì íŒŒì‹±
                clean_num = num_val.replace(',', '')
                try:
                    parsed_num = float(clean_num)
                    new_row = base_row.copy()
                    new_row['dimension_type'] = dim_type
                    new_row['parsed_value'] = parsed_num
                    new_row['needs_check'] = False
                    parsed_rows.append(new_row)
                except ValueError:
                    continue

        if parsed_rows:
            return parsed_rows, True, False
    
    # íŒ¨í„´ 1: valueì— ìˆ«ì(W), ìˆ«ì(H), ìˆ«ì(D), ìˆ«ì(L)ê°€ ëª…ì‹œëœ ê²½ìš°
    whd_pattern = r'([0-9,]+(?:\.[0-9]+)?)\s*(?:mm)?\s*\(?\s*([WwHhDdLl])\s*\)?'
    whd_matches = re.findall(whd_pattern, value)

    if len(whd_matches) >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ dimensionì´ ìˆëŠ” ê²½ìš°
        base_row = row.to_dict()
        dimension_map = {'w': 'width', 'h': 'height', 'd': 'depth', 'l': 'depth'}  # Lì„ depthë¡œ ë§¤í•‘

        for num_val, dim_letter in whd_matches:
            dim_type = dimension_map.get(dim_letter.lower())
            if dim_type:
                # ì½¤ë§ˆ ì œê±° í›„ ìˆ«ì íŒŒì‹±
                clean_num = num_val.replace(',', '')
                try:
                    parsed_num = float(clean_num)
                    new_row = base_row.copy()
                    new_row['dimension_type'] = dim_type
                    new_row['parsed_value'] = parsed_num
                    new_row['needs_check'] = False
                    parsed_rows.append(new_row)
                except ValueError:
                    continue

        if parsed_rows:
            return parsed_rows, True, False
    
    # íŒ¨í„´ 2: í•œê¸€ í‚¤ì›Œë“œë¡œ ìˆœì„œ ëª…ì‹œ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
    # value ë˜ëŠ” disp_nm2ì—ì„œ í‚¤ì›Œë“œ í™•ì¸
    # ì˜ˆ: disp_nm2="ë³¸ì²´ í¬ê¸° (ë„ˆë¹„xë‘ê»˜, mm)", value="7.0 x 2.6"

    combined_text = value + ' ' + disp_nm2  # ë‘ í•„ë“œë¥¼ í•©ì³ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰

    # ìˆ«ì ì¶”ì¶œ
    nums = re.findall(r'([0-9,]+(?:\.[0-9]+)?)', value)
    base_row = row.to_dict()

    # í‚¤ì›Œë“œ ìˆœì„œ íŒŒì‹±: disp_nm2ì—ì„œ í‚¤ì›Œë“œ ìˆœì„œëŒ€ë¡œ ì¶”ì¶œ
    # ì˜ˆ: "ê°€ë¡œxì„¸ë¡œxë‘ê»˜" â†’ ['ê°€ë¡œ', 'ì„¸ë¡œ', 'ë‘ê»˜']
    keyword_pattern = r'(ê°€ë¡œ|ì„¸ë¡œ|ë„ˆë¹„|í­|ë†’ì´|ë‘ê»˜|ê¹Šì´|ê¸¸ì´)'
    keyword_order = re.findall(keyword_pattern, disp_nm2)

    # í‚¤ì›Œë“œê°€ 2ê°œ ì´ìƒ ìˆê³ , ìˆ«ìë„ ì¶©ë¶„íˆ ìˆìœ¼ë©´ ìˆœì„œëŒ€ë¡œ ë§¤í•‘
    if len(keyword_order) >= 2 and len(nums) >= len(keyword_order):
        # í•œê¸€ í‚¤ì›Œë“œ â†’ dimension_type ë§¤í•‘ (ê¸°ë³¸ê°’)
        keyword_map = {
            'ê°€ë¡œ': 'width',
            'ë„ˆë¹„': 'width',
            'í­': 'width',
            'ì„¸ë¡œ': 'height',   # ê¸°ë³¸: ì„¸ë¡œ=height
            'ë†’ì´': 'height',
            'ë‘ê»˜': 'depth',
            'ê¹Šì´': 'depth',
            'ê¸¸ì´': 'depth',
        }

        # ì˜ˆì™¸ ì²˜ë¦¬: íŠ¹ì • ì¡°í•©ì—ì„œ ì„¸ë¡œì˜ ì˜ë¯¸ê°€ ë‹¬ë¼ì§
        # "ê°€ë¡œxë†’ì´xì„¸ë¡œ" íŒ¨í„´ â†’ ì„¸ë¡œë¥¼ depthë¡œ í•´ì„
        if 'ë†’ì´' in keyword_order and 'ì„¸ë¡œ' in keyword_order:
            # ë†’ì´ì™€ ì„¸ë¡œê°€ í•¨ê»˜ ìˆìœ¼ë©´, ì„¸ë¡œ=depth
            keyword_map['ì„¸ë¡œ'] = 'depth'

        try:
            for i, keyword in enumerate(keyword_order):
                if i < len(nums):
                    dim_type = keyword_map.get(keyword)
                    if dim_type:
                        parsed_rows.append({
                            **base_row,
                            'dimension_type': dim_type,
                            'parsed_value': float(nums[i].replace(',', '')),
                            'needs_check': False
                        })

            if parsed_rows:
                return parsed_rows, True, False
        except ValueError:
            pass

    # í‚¤ì›Œë“œ ìˆœì„œ íŒŒì‹± ì‹¤íŒ¨ ì‹œ, ê¸°ì¡´ ë¡œì§ ì‚¬ìš©

    # 2-1. 3ê°œ ê°’: ê°€ë¡œxë†’ì´xê¹Šì´ (ëª…ì‹œì )
    if 'ê°€ë¡œ' in combined_text and 'ë†’ì´' in combined_text and 'ê¹Šì´' in combined_text and len(nums) >= 3:
        try:
            parsed_rows.append({**base_row, 'dimension_type': 'width', 'parsed_value': float(nums[0].replace(',', '')), 'needs_check': False})
            parsed_rows.append({**base_row, 'dimension_type': 'height', 'parsed_value': float(nums[1].replace(',', '')), 'needs_check': False})
            parsed_rows.append({**base_row, 'dimension_type': 'depth', 'parsed_value': float(nums[2].replace(',', '')), 'needs_check': False})
            return parsed_rows, True, False
        except ValueError:
            pass

    # 2-2. 2ê°œ ê°’: ë„ˆë¹„xë‘ê»˜, ê°€ë¡œxë‘ê»˜, í­xë‘ê»˜, ê°€ë¡œxê¹Šì´ ë“±
    if ('ë„ˆë¹„' in combined_text or 'ê°€ë¡œ' in combined_text or 'í­' in combined_text) and ('ë‘ê»˜' in combined_text or 'ê¹Šì´' in combined_text):
        # ë†’ì´ í‚¤ì›Œë“œê°€ ì—†ì–´ì•¼ í•¨ (ìš°ì„ ìˆœìœ„ êµ¬ë¶„)
        if 'ë†’ì´' not in combined_text and len(nums) >= 2:
            try:
                parsed_rows.append({**base_row, 'dimension_type': 'width', 'parsed_value': float(nums[0].replace(',', '')), 'needs_check': False})
                # ë‘ê»˜/ê¹Šì´ëŠ” depth
                parsed_rows.append({**base_row, 'dimension_type': 'depth', 'parsed_value': float(nums[1].replace(',', '')), 'needs_check': False})
                return parsed_rows, True, False
            except ValueError:
                pass

    # 2-3. 2ê°œ ê°’: ë„ˆë¹„xë†’ì´, ê°€ë¡œxë†’ì´
    if ('ë„ˆë¹„' in combined_text or 'ê°€ë¡œ' in combined_text or 'í­' in combined_text) and 'ë†’ì´' in combined_text and len(nums) >= 2:
        try:
            parsed_rows.append({**base_row, 'dimension_type': 'width', 'parsed_value': float(nums[0].replace(',', '')), 'needs_check': False})
            parsed_rows.append({**base_row, 'dimension_type': 'height', 'parsed_value': float(nums[1].replace(',', '')), 'needs_check': False})
            return parsed_rows, True, False
        except ValueError:
            pass
    
    # íŒ¨í„´ 3: WxHxD í˜•ì‹ (xë¡œ êµ¬ë¶„, ë‹¨ìœ„ ëª…ì‹œ ì—†ìŒ) (ì˜ˆ: "180 x 70 x 72 mm", "223 x 96.5 x 94 mm")
    wxhxd_match = re.search(r'([0-9,]+(?:\.[0-9]+)?)\s*[xXÃ—]\s*([0-9,]+(?:\.[0-9]+)?)\s*[xXÃ—]\s*([0-9,]+(?:\.[0-9]+)?)', value)
    if wxhxd_match:
        val1, val2, val3 = wxhxd_match.groups()
        base_row = row.to_dict()

        # ê¸°ë³¸ ê°€ì •: ê°€ë¡œ x ë†’ì´ x ê¹Šì´
        dimensions = [
            ('width', val1),
            ('height', val2),
            ('depth', val3)
        ]

        try:
            for dim_type, val in dimensions:
                new_row = base_row.copy()
                new_row['dimension_type'] = dim_type
                new_row['parsed_value'] = float(val.replace(',', ''))
                new_row['needs_check'] = True  # ë‹¨ìœ„ê°€ ëª…í™•í•˜ì§€ ì•ŠìŒ
                parsed_rows.append(new_row)

            return parsed_rows, True, True
        except ValueError:
            pass
    
    # íŒ¨í„´ 4: WxH í˜•ì‹ (ì˜ˆ: "500x600 mm")
    wxh_match = re.search(r'([0-9,]+(?:\.[0-9]+)?)\s*[xXÃ—]\s*([0-9,]+(?:\.[0-9]+)?)', value)
    if wxh_match:
        val1, val2 = wxh_match.groups()
        base_row = row.to_dict()

        # ê¸°ë³¸ ê°€ì •: ê°€ë¡œ x ë†’ì´
        dimensions = [
            ('width', val1),
            ('height', val2)
        ]

        try:
            for dim_type, val in dimensions:
                new_row = base_row.copy()
                new_row['dimension_type'] = dim_type
                new_row['parsed_value'] = float(val.replace(',', ''))
                new_row['needs_check'] = True  # ë‹¨ìœ„ê°€ ëª…í™•í•˜ì§€ ì•ŠìŒ
                parsed_rows.append(new_row)

            return parsed_rows, True, True
        except ValueError:
            pass
    
    # íŒ¨í„´ 5: ë‹¨ì¼ ê°’ (disp_nm2ì—ì„œ dimension íƒ€ì… ì‹ë³„)
    single_match = re.search(r'([0-9,]+(?:\.[0-9]+)?)', value)
    if single_match:
        dim_type = identify_dimension_type(disp_nm2)
        if dim_type:
            try:
                clean_num = single_match.group(1).replace(',', '')
                parsed_num = float(clean_num)
                base_row = row.to_dict()
                base_row['dimension_type'] = dim_type
                base_row['parsed_value'] = parsed_num
                base_row['needs_check'] = False
                parsed_rows.append(base_row)
                return parsed_rows, True, False
            except ValueError:
                pass
    
    return parsed_rows, False, False

# ============================================
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ============================================

def process_spec_data_with_validation(engine, truncate_before_insert=True, verbose=True):
    """
    ê²€ì¦ ê·œì¹™ ê¸°ë°˜ ìŠ¤í™ ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Parameters:
    -----------
    engine : SQLAlchemy engine
        ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    truncate_before_insert : bool
        Trueì´ë©´ mod í…Œì´ë¸”ì˜ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì‚½ì…
    verbose : bool
        ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    bool : ì„±ê³µ ì—¬ë¶€
    """
    try:
        # 1. validation ê·œì¹™ ë¡œë“œ
        print("\n" + "="*80)
        print("ğŸ“¥ ê²€ì¦ ê·œì¹™ ë¡œë“œ ì¤‘...")
        print("="*80)
        validation_rules = load_validation_rules(engine)

        if validation_rules is None or len(validation_rules) == 0:
            print("\nâš ï¸ ì²˜ë¦¬í•  ê²€ì¦ ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤ (is_target=true, is_completed=false)")
            return True

        # 2. ê²€ì¦ ê·œì¹™ì— ë§¤ì¹­ë˜ëŠ” ë°ì´í„° ë¡œë“œ
        print("\n" + "="*80)
        print("ğŸ“¥ ì†ŒìŠ¤ ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("="*80)
        df_filtered = load_data_with_validation_rules(engine, validation_rules)

        if df_filtered is None or len(df_filtered) == 0:
            print("\nâŒ ë§¤ì¹­ë˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return False

        # 3. ë°ì´í„° íŒŒì‹±
        print("\n" + "="*80)
        print("ğŸ”„ ë°ì´í„° íŒŒì‹± ì¤‘...")
        print("="*80)

        parsed_data = []
        parsed_results = {}  # {validation_rule_id: success}
        unparsed_data = []

        for _, row in df_filtered.iterrows():
            parsed_rows, success, needs_check = parse_dimensions_advanced(row)
            rule_id = row['validation_rule_id']

            if success and parsed_rows:
                # validation_rule_idì™€ target_disp_nm2 ì¶”ê°€
                for parsed_row in parsed_rows:
                    parsed_row['validation_rule_id'] = rule_id
                    parsed_row['target_disp_nm2'] = row['target_disp_nm2']

                parsed_data.extend(parsed_rows)
                parsed_results[rule_id] = True
            else:
                unparsed_data.append(row)
                if rule_id not in parsed_results:
                    parsed_results[rule_id] = False

        df_parsed = pd.DataFrame(parsed_data)
        df_unparsed = pd.DataFrame(unparsed_data)

        # íŒŒì‹± í†µê³„ ì¶œë ¥
        successful_rules = len([v for v in parsed_results.values() if v])
        total_rules = len(validation_rules)
        print(f"âœ… íŒŒì‹± ì„±ê³µ: {len(df_parsed)}ê°œ dimension ê°’")
        print(f"âœ… ì„±ê³µí•œ ê²€ì¦ ê·œì¹™: {successful_rules}/{total_rules}ê°œ")
        print(f"âŒ íŒŒì‹± ì‹¤íŒ¨: {len(df_unparsed)}ê°œ í–‰")
        print(f"ğŸ“ˆ ì „ì²´ ëŒ€ë¹„ íŒŒì‹±ë¥ : {(len(df_parsed) / len(df_filtered) * 100 if len(df_filtered) > 0 else 0):.1f}%")

        # ìƒì„¸ ì¶œë ¥ (verbose ëª¨ë“œ)
        if verbose and len(df_parsed) > 0:
            print("\nâœ… íŒŒì‹± ì„±ê³µ ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 20ê°œ):")
            print("-" * 80)
            display_cols = ['mdl_code', 'goods_nm', 'disp_nm1', 'disp_nm2', 'target_disp_nm2', 'dimension_type', 'parsed_value', 'value']
            available_cols = [col for col in display_cols if col in df_parsed.columns]
            print(df_parsed[available_cols].head(20).to_string())

        # 4. Mod í…Œì´ë¸”ì— ì €ì¥
        print("\n" + "="*80)
        print("ğŸ’¾ Mod í…Œì´ë¸”ì— ì €ì¥ ì¤‘...")
        print("="*80)

        if truncate_before_insert:
            truncate_table(engine, MOD_TABLE)

        success_mod = save_to_mod_table(engine, df_parsed)

        # 5. Staging í…Œì´ë¸” ì—…ë°ì´íŠ¸
        print("\n" + "="*80)
        print("ğŸ’¾ Staging í…Œì´ë¸” ì—…ë°ì´íŠ¸ ì¤‘...")
        print("="*80)

        # validation_rule_idë³„ë¡œ dimension_type ì§‘ê³„
        dimension_summaries = {}
        if len(df_parsed) > 0:
            dimension_summaries = df_parsed.groupby('validation_rule_id')['dimension_type'].apply(
                lambda x: sorted(list(set(x)))
            ).to_dict()

        success_staging = update_staging_table(engine, validation_rules, parsed_results, dimension_summaries)

        success = success_mod and success_staging

        if success:
            print("\n" + "="*80)
            print("âœ… ì „ì²´ ì‘ì—… ì™„ë£Œ!")
            print("="*80)
            print(f"ğŸ“Š ìš”ì•½:")
            print(f"  - ì²˜ë¦¬ëœ ê²€ì¦ ê·œì¹™: {successful_rules}/{total_rules}ê°œ")
            print(f"  - íŒŒì‹±ëœ dimension ê°’: {len(df_parsed)}ê°œ")
            print(f"  - Staging í…Œì´ë¸” ì—…ë°ì´íŠ¸: ì™„ë£Œ")
            print(f"  - Mod í…Œì´ë¸” ì €ì¥: ì™„ë£Œ")
            return True
        else:
            print("\nâŒ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨")
            return False

    except Exception as e:
        print(f"\nâŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False



def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description='PostgreSQL ìŠ¤í™ ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ (ê²€ì¦ ê·œì¹™ ê¸°ë°˜)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ì˜ˆì œ:
  python transform_spec.py                     # ê¸°ë³¸ ì‹¤í–‰
  python transform_spec.py --no-truncate       # mod í…Œì´ë¸” ë°ì´í„° ìœ ì§€
  python transform_spec.py --quiet             # ê°„ëµí•œ ì¶œë ¥
        '''
    )

    parser.add_argument('--no-truncate', action='store_true', help='mod í…Œì´ë¸” ê¸°ì¡´ ë°ì´í„° ìœ ì§€')
    parser.add_argument('--quiet', '-q', action='store_true', help='ê°„ëµí•œ ì¶œë ¥ë§Œ í‘œì‹œ')

    args = parser.parse_args()

    truncate_before_insert = not args.no_truncate
    verbose = not args.quiet

    print("\nğŸš€ PostgreSQL ìŠ¤í™ ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸ (ê²€ì¦ ê·œì¹™ ê¸°ë°˜)")
    print("="*80)

    # ì„¤ì • í™•ì¸
    print("\n" + "="*80)
    print("ì‹¤í–‰ ì„¤ì • í™•ì¸")
    print("="*80)
    print(f"Staging í…Œì´ë¸”: {STAGING_TABLE}")
    print(f"ì†ŒìŠ¤ í…Œì´ë¸”: {SOURCE_TABLE}")
    print(f"Mod í…Œì´ë¸”: {MOD_TABLE}")
    print(f"ê¸°ì¡´ ë°ì´í„° ì‚­ì œ: {'ì˜ˆ' if truncate_before_insert else 'ì•„ë‹ˆì˜¤'}")
    print(f"ìƒì„¸ ì¶œë ¥: {'ì˜ˆ' if verbose else 'ì•„ë‹ˆì˜¤'}")

    confirm = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if confirm != 'y':
        print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return

    # ì—”ì§„ ìƒì„±
    engine = get_sqlalchemy_engine()
    if engine is None:
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
        sys.exit(1)

    try:
        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        success = process_spec_data_with_validation(
            engine=engine,
            truncate_before_insert=truncate_before_insert,
            verbose=verbose
        )

        # ì¢…ë£Œ ì½”ë“œ ë°˜í™˜
        sys.exit(0 if success else 1)
    finally:
        engine.dispose()

if __name__ == "__main__":
    main()