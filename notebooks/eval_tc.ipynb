{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb7fc6c6",
   "metadata": {},
   "source": [
    "### TCë¡œ ë§Œë“  Text2SQL ê²°ê³¼ë¥¼ í‰ê°€í•œë‹¤. \n",
    "#### product_id listë¥¼ ë°›ì•„, ì •ë‹µì…‹ê³¼ ë¹„êµí•˜ì—¬ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb50f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL ì—°ê²° ì •ë³´:\n",
      "   Host: dev-rubicon-postgresql.postgres.database.azure.com\n",
      "   Port: 5432\n",
      "\n",
      "âœ… PostgreSQL ì„¤ì • ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# CREATE TABLE IF NOT EXISTS tc_check_table_20251015 (\n",
    "# \tid SERIAL PRIMARY KEY,\n",
    "#   query_number INT,\n",
    "# \tcategory VARCHAR(15),\n",
    "# \tinstruction TEXT,\n",
    "# \tquery TEXT,\n",
    "# \tproduct_id_list TEXT[],\n",
    "# \tcreated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "# );\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "\n",
    "load_dotenv('.env')\n",
    "\n",
    "# PostgreSQL ì„¤ì • ë¡œë“œ\n",
    "PG_HOST = os.getenv('PG_HOST')\n",
    "PG_PORT = os.getenv('PG_PORT')\n",
    "PG_DATABASE = os.getenv('PG_DATABASE')\n",
    "PG_USER = os.getenv('PG_USER')\n",
    "PG_PASSWORD = os.getenv('PG_PASSWORD')\n",
    "\n",
    "print(f\"PostgreSQL ì—°ê²° ì •ë³´:\")\n",
    "print(f\"   Host: {PG_HOST}\")\n",
    "print(f\"   Port: {PG_PORT}\")\n",
    "\n",
    "# SQLAlchemy ì—°ê²° ë¬¸ìì—´ ìƒì„±\n",
    "POSTGRES_URL = f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DATABASE}\"\n",
    "\n",
    "print(f\"\\nâœ… PostgreSQL ì„¤ì • ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "def get_db_connection():\n",
    "    \"\"\"PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return psycopg2.connect(\n",
    "            host=PG_HOST,\n",
    "            port=PG_PORT,\n",
    "            database=PG_DATABASE,\n",
    "            user=PG_USER,\n",
    "            password=PG_PASSWORD\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5154e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class Text2SQLEvaluator:\n",
    "    \"\"\"Text2SQL í‰ê°€ë¥¼ ìœ„í•œ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connection = None\n",
    "        self.evaluation_results = []\n",
    "        \n",
    "    def connect_db(self):\n",
    "        \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°\"\"\"\n",
    "        try:\n",
    "            self.connection = get_db_connection()\n",
    "            print(\"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def close_connection(self):\n",
    "        \"\"\"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ\"\"\"\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "            print(\"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ\")\n",
    "    \n",
    "    def get_ground_truth(self, query_number: int) -> Tuple[Optional[List[str]], Optional[str], Optional[str]]:\n",
    "        \"\"\"\n",
    "        ì •ë‹µ product_id list ì¡°íšŒ\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (product_id_list, category, instruction)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            query = \"\"\"\n",
    "                SELECT product_id_list, category, instruction\n",
    "                FROM tc_check_table_20251015\n",
    "                WHERE query_number = %s\n",
    "            \"\"\"\n",
    "            cursor.execute(query, (query_number,))\n",
    "            result = cursor.fetchone()\n",
    "            cursor.close()\n",
    "            \n",
    "            if result:\n",
    "                return result[0], result[1], result[2]\n",
    "            else:\n",
    "                print(f\"âš ï¸ ì¿¼ë¦¬ ë²ˆí˜¸ {query_number}ì— ëŒ€í•œ ì •ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                return None, None, None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì •ë‹µ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "            return None, None, None\n",
    "    \n",
    "    def calculate_metrics(self, predicted: List[str], ground_truth: List[str]) -> Dict:\n",
    "        \"\"\"\n",
    "        ì˜ˆì¸¡ ê²°ê³¼ì™€ ì •ë‹µì„ ë¹„êµí•˜ì—¬ í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "        \n",
    "        Args:\n",
    "            predicted: ì˜ˆì¸¡ëœ product_id ë¦¬ìŠ¤íŠ¸\n",
    "            ground_truth: ì •ë‹µ product_id ë¦¬ìŠ¤íŠ¸\n",
    "            \n",
    "        Returns:\n",
    "            í‰ê°€ ì§€í‘œ ë”•ì…”ë„ˆë¦¬\n",
    "        \"\"\"\n",
    "        # Setìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¹„êµ\n",
    "        pred_set = set(predicted) if predicted else set()\n",
    "        truth_set = set(ground_truth) if ground_truth else set()\n",
    "        \n",
    "        # True Positives: ì˜ˆì¸¡ê³¼ ì •ë‹µ ëª¨ë‘ì— ìˆëŠ” í•­ëª©\n",
    "        tp = len(pred_set.intersection(truth_set))\n",
    "        \n",
    "        # False Positives: ì˜ˆì¸¡ì—ë§Œ ìˆê³  ì •ë‹µì—ëŠ” ì—†ëŠ” í•­ëª©\n",
    "        fp = len(pred_set - truth_set)\n",
    "        \n",
    "        # False Negatives: ì •ë‹µì—ë§Œ ìˆê³  ì˜ˆì¸¡ì—ëŠ” ì—†ëŠ” í•­ëª©\n",
    "        fn = len(truth_set - pred_set)\n",
    "        \n",
    "        # True NegativesëŠ” product_id ì „ì²´ ì§‘í•©ì„ ì•Œì•„ì•¼ ê³„ì‚° ê°€ëŠ¥\n",
    "        # ì—¬ê¸°ì„œëŠ” ê´€ë ¨ ì—†ëŠ” product_idì˜ ìˆ˜ë¥¼ ëª¨ë¥´ë¯€ë¡œ ìƒëµ\n",
    "        \n",
    "        # Precision, Recall, F1 Score ê³„ì‚°\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        # Exact Match (ì™„ì „ ì¼ì¹˜ ì—¬ë¶€)\n",
    "        exact_match = 1 if pred_set == truth_set else 0\n",
    "        \n",
    "        # Jaccard Similarity (IoU)\n",
    "        jaccard = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'TP': tp,\n",
    "            'FP': fp,\n",
    "            'FN': fn,\n",
    "            'Precision': round(precision, 4),\n",
    "            'Recall': round(recall, 4),\n",
    "            'F1_Score': round(f1_score, 4),\n",
    "            'Exact_Match': exact_match,\n",
    "            'Jaccard_Similarity': round(jaccard, 4),\n",
    "            'Predicted_Count': len(pred_set),\n",
    "            'Ground_Truth_Count': len(truth_set)\n",
    "        }\n",
    "    \n",
    "    def evaluate_single_query(self, query_number: int, predicted_ids: List[str], \n",
    "                            verbose: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        ë‹¨ì¼ ì¿¼ë¦¬ì— ëŒ€í•œ í‰ê°€ ìˆ˜í–‰\n",
    "        \n",
    "        Args:\n",
    "            query_number: ì¿¼ë¦¬ ë²ˆí˜¸\n",
    "            predicted_ids: ì˜ˆì¸¡ëœ product_id ë¦¬ìŠ¤íŠ¸\n",
    "            verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€\n",
    "            \n",
    "        Returns:\n",
    "            í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬\n",
    "        \"\"\"\n",
    "        # ì •ë‹µ ì¡°íšŒ\n",
    "        ground_truth_ids, category, instruction = self.get_ground_truth(query_number)\n",
    "        \n",
    "        if ground_truth_ids is None:\n",
    "            return None\n",
    "        \n",
    "        # í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "        metrics = self.calculate_metrics(predicted_ids, ground_truth_ids)\n",
    "        \n",
    "        # ê²°ê³¼ì— ë©”íƒ€ ì •ë³´ ì¶”ê°€\n",
    "        result = {\n",
    "            'query_number': query_number,\n",
    "            'category': category,\n",
    "            'instruction': instruction[:50] + '...' if instruction and len(instruction) > 50 else instruction,\n",
    "            **metrics\n",
    "        }\n",
    "        \n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        self.evaluation_results.append(result)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"ì¿¼ë¦¬ ë²ˆí˜¸: {query_number}\")\n",
    "            print(f\"ì¹´í…Œê³ ë¦¬: {category}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"ì˜ˆì¸¡ëœ product_id ìˆ˜: {metrics['Predicted_Count']}\")\n",
    "            print(f\"ì •ë‹µ product_id ìˆ˜: {metrics['Ground_Truth_Count']}\")\n",
    "            print(f\"\\n[í‰ê°€ ì§€í‘œ]\")\n",
    "            print(f\"  - TP (True Positives): {metrics['TP']}\")\n",
    "            print(f\"  - FP (False Positives): {metrics['FP']}\")\n",
    "            print(f\"  - FN (False Negatives): {metrics['FN']}\")\n",
    "            print(f\"  - Precision: {metrics['Precision']:.2%}\")\n",
    "            print(f\"  - Recall: {metrics['Recall']:.2%}\")\n",
    "            print(f\"  - F1 Score: {metrics['F1_Score']:.2%}\")\n",
    "            print(f\"  - Exact Match: {'âœ…' if metrics['Exact_Match'] else 'âŒ'}\")\n",
    "            print(f\"  - Jaccard Similarity: {metrics['Jaccard_Similarity']:.2%}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def evaluate_batch(self, query_predictions: List[Tuple[int, List[str]]], \n",
    "                      verbose: bool = False) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        ì—¬ëŸ¬ ì¿¼ë¦¬ì— ëŒ€í•œ ì¼ê´„ í‰ê°€\n",
    "        \n",
    "        Args:\n",
    "            query_predictions: [(query_number, predicted_ids), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸\n",
    "            verbose: ê° ì¿¼ë¦¬ë³„ ìƒì„¸ ì¶œë ¥ ì—¬ë¶€\n",
    "            \n",
    "        Returns:\n",
    "            í‰ê°€ ê²°ê³¼ DataFrame\n",
    "        \"\"\"\n",
    "        # í‰ê°€ ì‹œì‘ ì „ì— ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŒ (ëˆ„ì  í‰ê°€ë¥¼ ìœ„í•´)\n",
    "        batch_results = []\n",
    "        \n",
    "        for query_number, predicted_ids in query_predictions:\n",
    "            result = self.evaluate_single_query(query_number, predicted_ids, verbose)\n",
    "            if result:\n",
    "                batch_results.append(result)\n",
    "        \n",
    "        # ë°°ì¹˜ ê²°ê³¼ë§Œ DataFrameìœ¼ë¡œ ë°˜í™˜\n",
    "        return pd.DataFrame(batch_results)\n",
    "    \n",
    "    def get_overall_metrics(self) -> Dict:\n",
    "        \"\"\"\n",
    "        ì „ì²´ í‰ê°€ ê²°ê³¼ ìš”ì•½\n",
    "        \n",
    "        Returns:\n",
    "            ì „ì²´ í‰ê°€ ì§€í‘œ ë”•ì…”ë„ˆë¦¬\n",
    "        \"\"\"\n",
    "        if not self.evaluation_results:\n",
    "            print(\"í‰ê°€ëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(self.evaluation_results)\n",
    "        \n",
    "        # ì¤‘ë³µ ì œê±° (ê°™ì€ query_numberê°€ ì—¬ëŸ¬ ë²ˆ í‰ê°€ëœ ê²½ìš° ìµœì‹  ê²°ê³¼ë§Œ ì‚¬ìš©)\n",
    "        df = df.drop_duplicates(subset=['query_number'], keep='last')\n",
    "        \n",
    "        # ì „ì²´ í†µê³„\n",
    "        total_tp = df['TP'].sum()\n",
    "        total_fp = df['FP'].sum()\n",
    "        total_fn = df['FN'].sum()\n",
    "        \n",
    "        # Micro-averaged metrics (ì „ì²´ TP, FP, FN ê¸°ì¤€)\n",
    "        micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
    "        micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
    "        micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (micro_precision + micro_recall) > 0 else 0\n",
    "        \n",
    "        # Macro-averaged metrics (ê° ì¿¼ë¦¬ë³„ í‰ê· )\n",
    "        macro_precision = df['Precision'].mean()\n",
    "        macro_recall = df['Recall'].mean()\n",
    "        macro_f1 = df['F1_Score'].mean()\n",
    "        \n",
    "        # ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥\n",
    "        category_metrics = None\n",
    "        if 'category' in df.columns and df['category'].notna().any():\n",
    "            category_metrics = df.groupby('category').agg({\n",
    "                'Precision': 'mean',\n",
    "                'Recall': 'mean',\n",
    "                'F1_Score': 'mean',\n",
    "                'Exact_Match': 'mean',\n",
    "                'query_number': 'count'\n",
    "            }).round(4)\n",
    "            category_metrics.rename(columns={'query_number': 'Count'}, inplace=True)\n",
    "        \n",
    "        overall_metrics = {\n",
    "            'total_queries': len(df),\n",
    "            'total_tp': int(total_tp),\n",
    "            'total_fp': int(total_fp),\n",
    "            'total_fn': int(total_fn),\n",
    "            'micro_precision': round(micro_precision, 4),\n",
    "            'micro_recall': round(micro_recall, 4),\n",
    "            'micro_f1': round(micro_f1, 4),\n",
    "            'macro_precision': round(macro_precision, 4),\n",
    "            'macro_recall': round(macro_recall, 4),\n",
    "            'macro_f1': round(macro_f1, 4),\n",
    "            'exact_match_rate': round(df['Exact_Match'].mean(), 4),\n",
    "            'avg_jaccard': round(df['Jaccard_Similarity'].mean(), 4),\n",
    "            'category_metrics': category_metrics\n",
    "        }\n",
    "        \n",
    "        return overall_metrics\n",
    "    \n",
    "    def print_overall_report(self):\n",
    "        \"\"\"\n",
    "        ì „ì²´ í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "        \"\"\"\n",
    "        metrics = self.get_overall_metrics()\n",
    "        \n",
    "        if not metrics:\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\" \" * 25 + \"ğŸ“Š ì „ì²´ í‰ê°€ ê²°ê³¼\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"\\n[í‰ê°€ ëŒ€ìƒ]\")\n",
    "        print(f\"  ì´ ì¿¼ë¦¬ ìˆ˜: {metrics['total_queries']}ê°œ\")\n",
    "        \n",
    "        print(f\"\\n[ì „ì²´ í†µê³„]\")\n",
    "        print(f\"  - Total TP: {metrics['total_tp']}\")\n",
    "        print(f\"  - Total FP: {metrics['total_fp']}\")\n",
    "        print(f\"  - Total FN: {metrics['total_fn']}\")\n",
    "        \n",
    "        print(f\"\\n[Micro-averaged Metrics] (ì „ì²´ TP, FP, FN ê¸°ì¤€)\")\n",
    "        print(f\"  - Precision: {metrics['micro_precision']:.2%}\")\n",
    "        print(f\"  - Recall: {metrics['micro_recall']:.2%}\")\n",
    "        print(f\"  - F1 Score: {metrics['micro_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n[Macro-averaged Metrics] (ì¿¼ë¦¬ë³„ í‰ê· )\")\n",
    "        print(f\"  - Precision: {metrics['macro_precision']:.2%}\")\n",
    "        print(f\"  - Recall: {metrics['macro_recall']:.2%}\")\n",
    "        print(f\"  - F1 Score: {metrics['macro_f1']:.2%}\")\n",
    "        \n",
    "        print(f\"\\n[ì¶”ê°€ ì§€í‘œ]\")\n",
    "        print(f\"  - Exact Match Rate: {metrics['exact_match_rate']:.2%}\")\n",
    "        print(f\"  - Average Jaccard Similarity: {metrics['avg_jaccard']:.2%}\")\n",
    "        \n",
    "        if metrics['category_metrics'] is not None:\n",
    "            print(f\"\\n[ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥]\")\n",
    "            print(metrics['category_metrics'].to_string())\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    def save_results(self, filename: str = None):\n",
    "        \"\"\"\n",
    "        í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥\n",
    "        \n",
    "        Args:\n",
    "            filename: ì €ì¥í•  íŒŒì¼ëª… (ê¸°ë³¸ê°’: text2sql_eval_YYYYMMDD_HHMMSS.csv)\n",
    "        \"\"\"\n",
    "        if not self.evaluation_results:\n",
    "            print(\"ì €ì¥í•  í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        if filename is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"text2sql_eval_{timestamp}.csv\"\n",
    "        \n",
    "        df = pd.DataFrame(self.evaluation_results)\n",
    "        # ì¤‘ë³µ ì œê±°\n",
    "        df = df.drop_duplicates(subset=['query_number'], keep='last')\n",
    "        df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "        print(f\"âœ… í‰ê°€ ê²°ê³¼ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ {len(df)}ê°œ ì¿¼ë¦¬)\")\n",
    "    \n",
    "    def reset_results(self):\n",
    "        \"\"\"í‰ê°€ ê²°ê³¼ ì´ˆê¸°í™”\"\"\"\n",
    "        self.evaluation_results = []\n",
    "        print(\"í‰ê°€ ê²°ê³¼ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    def get_results_dataframe(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        í˜„ì¬ê¹Œì§€ì˜ í‰ê°€ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜\n",
    "        \n",
    "        Returns:\n",
    "            í‰ê°€ ê²°ê³¼ DataFrame\n",
    "        \"\"\"\n",
    "        if not self.evaluation_results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(self.evaluation_results)\n",
    "        # ì¤‘ë³µ ì œê±°\n",
    "        df = df.drop_duplicates(subset=['query_number'], keep='last')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ho4l4evvwa",
   "metadata": {},
   "source": [
    "## ì‚¬ìš© ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7l73zlacder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í‰ê°€ê¸° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "evaluator = Text2SQLEvaluator()\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°\n",
    "evaluator.connect_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o9tsc77xg1j",
   "metadata": {},
   "source": [
    "### 1. ë‹¨ì¼ ì¿¼ë¦¬ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9z5diwxsn0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ì¿¼ë¦¬ ë²ˆí˜¸: 1\n",
      "ì¹´í…Œê³ ë¦¬: ê°€ê²©\n",
      "============================================================\n",
      "ì˜ˆì¸¡ëœ product_id ìˆ˜: 4\n",
      "ì •ë‹µ product_id ìˆ˜: 18\n",
      "\n",
      "[í‰ê°€ ì§€í‘œ]\n",
      "  - TP (True Positives): 0\n",
      "  - FP (False Positives): 4\n",
      "  - FN (False Negatives): 18\n",
      "  - Precision: 0.00%\n",
      "  - Recall: 0.00%\n",
      "  - F1 Score: 0.00%\n",
      "  - Exact Match: âŒ\n",
      "  - Jaccard Similarity: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì‹œ: ì¿¼ë¦¬ ë²ˆí˜¸ 1ì— ëŒ€í•œ í‰ê°€\n",
    "query_number = 1\n",
    "predicted_product_ids = ['P001', 'P002', 'P003', 'P005']  # ì˜ˆì¸¡ëœ product_id ë¦¬ìŠ¤íŠ¸\n",
    "# predicted_product_ids = ['P001', 'P002', 'P003', 'P005', 'G000430069']  # ì˜ˆì¸¡ëœ product_id ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "# ë‹¨ì¼ ì¿¼ë¦¬ í‰ê°€ ì‹¤í–‰\n",
    "result = evaluator.evaluate_single_query(query_number, predicted_product_ids, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raozhv24zih",
   "metadata": {},
   "source": [
    "### 2. ì—¬ëŸ¬ ì¿¼ë¦¬ ì¼ê´„ í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145wath4pf8j",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ní‰ê°€ ê²°ê³¼ DataFrame:\n",
      "   query_number category                   instruction  TP  FP  FN  Precision  \\\n",
      "0             1       ê°€ê²©              ê°¤ëŸ­ì‹œ S25 ê°€ê²© ì•Œë ¤ì£¼ì„¸ìš”   0   3  18        0.0   \n",
      "1             2       ê°€ê²©   ê°¤ëŸ­ì‹œ S25 512GB ì˜µì…˜ì€ ê°€ê²©ì´ ì–¼ë§ˆì˜ˆìš”?   0   4   7        0.0   \n",
      "2             3       ê°€ê²©  ê°¤ëŸ­ì‹œ S25 512GB í•‘í¬ê³¨ë“œëŠ” ê°€ê²©ì´ ì–¼ë§ˆì•¼?   0   2   1        0.0   \n",
      "\n",
      "   Recall  F1_Score  Exact_Match  Jaccard_Similarity  Predicted_Count  \\\n",
      "0     0.0         0            0                 0.0                3   \n",
      "1     0.0         0            0                 0.0                4   \n",
      "2     0.0         0            0                 0.0                2   \n",
      "\n",
      "   Ground_Truth_Count  \n",
      "0                  18  \n",
      "1                   7  \n",
      "2                   1  \n"
     ]
    }
   ],
   "source": [
    "# ì—¬ëŸ¬ ì¿¼ë¦¬ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ ì¤€ë¹„\n",
    "# í˜•ì‹: [(query_number, [predicted_product_ids]), ...]\n",
    "batch_predictions = [\n",
    "    (1, ['P001', 'P002', 'P003']),\n",
    "    (2, ['P010', 'P011', 'P012', 'P013']),\n",
    "    (3, ['P020', 'P021']),\n",
    "    # ... ë” ë§ì€ ì¿¼ë¦¬ë“¤\n",
    "]\n",
    "\n",
    "# ì¼ê´„ í‰ê°€ ì‹¤í–‰ (verbose=Falseë¡œ ê°œë³„ ì¶œë ¥ ìƒëµ)\n",
    "results_df = evaluator.evaluate_batch(batch_predictions, verbose=False)\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"\\\\ní‰ê°€ ê²°ê³¼ DataFrame:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olaud9o4gag",
   "metadata": {},
   "source": [
    "### 3. 100ê°œ ì¿¼ë¦¬ í‰ê°€ ì‹œë®¬ë ˆì´ì…˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ednrddpqsc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í‰ê°€ ê²°ê³¼ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "100ê°œ ì¿¼ë¦¬ í‰ê°€ ì‹œì‘...\n",
      "âœ… 100ê°œ ì¿¼ë¦¬ í‰ê°€ ì™„ë£Œ\n",
      "\\n[ì²˜ìŒ 5ê°œ ì¿¼ë¦¬ í‰ê°€ ê²°ê³¼]\n",
      "   query_number category                   instruction  TP  FP  FN  Precision  \\\n",
      "0             1       ê°€ê²©              ê°¤ëŸ­ì‹œ S25 ê°€ê²© ì•Œë ¤ì£¼ì„¸ìš”   0   4  18        0.0   \n",
      "1             2       ê°€ê²©   ê°¤ëŸ­ì‹œ S25 512GB ì˜µì…˜ì€ ê°€ê²©ì´ ì–¼ë§ˆì˜ˆìš”?   0   3   7        0.0   \n",
      "2             3       ê°€ê²©  ê°¤ëŸ­ì‹œ S25 512GB í•‘í¬ê³¨ë“œëŠ” ê°€ê²©ì´ ì–¼ë§ˆì•¼?   0   4   1        0.0   \n",
      "3             4       ê°€ê²©                ë¹„ìŠ¤í¬í¬ ai ì„¸íƒê¸° ê°€ê²©   0   7  32        0.0   \n",
      "4             5       ê°€ê²©            S25ë‘ í”ŒëŸ¬ìŠ¤ ê°€ê²© ë¹„êµí•´ì£¼ì„¸ì—¬   0   7  36        0.0   \n",
      "\n",
      "   Recall  F1_Score  Exact_Match  Jaccard_Similarity  Predicted_Count  \\\n",
      "0     0.0         0            0                 0.0                4   \n",
      "1     0.0         0            0                 0.0                3   \n",
      "2     0.0         0            0                 0.0                4   \n",
      "3     0.0         0            0                 0.0                7   \n",
      "4     0.0         0            0                 0.0                7   \n",
      "\n",
      "   Ground_Truth_Count  \n",
      "0                  18  \n",
      "1                   7  \n",
      "2                   1  \n",
      "3                  32  \n",
      "4                  36  \n"
     ]
    }
   ],
   "source": [
    "# 100ê°œ ì¿¼ë¦¬ì— ëŒ€í•œ í‰ê°€ ì˜ˆì‹œ\n",
    "# ì‹¤ì œ ì‚¬ìš©ì‹œì—ëŠ” Text2SQL ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©\n",
    "\n",
    "# ì˜ˆì‹œ: 100ê°œ ì¿¼ë¦¬ì— ëŒ€í•œ ì˜ˆì¸¡ ê²°ê³¼ (ì—¬ê¸°ì„œëŠ” ë”ë¯¸ ë°ì´í„° ìƒì„±)\n",
    "all_predictions = []\n",
    "for query_num in range(1, 101):\n",
    "    # ì‹¤ì œë¡œëŠ” ê° ì¿¼ë¦¬ì— ëŒ€í•œ Text2SQL ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì—¬ê¸°ì— ì…ë ¥\n",
    "    predicted_ids = [f'P{query_num:03d}_{i}' for i in range(np.random.randint(1, 10))]\n",
    "    all_predictions.append((query_num, predicted_ids))\n",
    "\n",
    "# í‰ê°€ ê²°ê³¼ ì´ˆê¸°í™” (ì´ì „ ê²°ê³¼ ì‚­ì œ)\n",
    "evaluator.reset_results()\n",
    "\n",
    "# 100ê°œ ì¿¼ë¦¬ ì¼ê´„ í‰ê°€\n",
    "print(\"100ê°œ ì¿¼ë¦¬ í‰ê°€ ì‹œì‘...\")\n",
    "results_df_100 = evaluator.evaluate_batch(all_predictions[:100], verbose=False)\n",
    "print(f\"âœ… {len(results_df_100)}ê°œ ì¿¼ë¦¬ í‰ê°€ ì™„ë£Œ\")\n",
    "\n",
    "# ê°œë³„ ì¿¼ë¦¬ ê²°ê³¼ ìƒ˜í”Œ í™•ì¸\n",
    "print(\"\\\\n[ì²˜ìŒ 5ê°œ ì¿¼ë¦¬ í‰ê°€ ê²°ê³¼]\")\n",
    "print(results_df_100.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ic41gcxuxjn",
   "metadata": {},
   "source": [
    "### 4. ì „ì²´ í‰ê°€ ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dkaxxahcp5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "                         ğŸ“Š ì „ì²´ í‰ê°€ ê²°ê³¼\n",
      "======================================================================\n",
      "\n",
      "[í‰ê°€ ëŒ€ìƒ]\n",
      "  ì´ ì¿¼ë¦¬ ìˆ˜: 100ê°œ\n",
      "\n",
      "[ì „ì²´ í†µê³„]\n",
      "  - Total TP: 0\n",
      "  - Total FP: 514\n",
      "  - Total FN: 2846\n",
      "\n",
      "[Micro-averaged Metrics] (ì „ì²´ TP, FP, FN ê¸°ì¤€)\n",
      "  - Precision: 0.00%\n",
      "  - Recall: 0.00%\n",
      "  - F1 Score: 0.00%\n",
      "\n",
      "[Macro-averaged Metrics] (ì¿¼ë¦¬ë³„ í‰ê· )\n",
      "  - Precision: 0.00%\n",
      "  - Recall: 0.00%\n",
      "  - F1 Score: 0.00%\n",
      "\n",
      "[ì¶”ê°€ ì§€í‘œ]\n",
      "  - Exact Match Rate: 0.00%\n",
      "  - Average Jaccard Similarity: 0.00%\n",
      "\n",
      "[ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥]\n",
      "          Precision  Recall  F1_Score  Exact_Match  Count\n",
      "category                                                 \n",
      "ê°€ê²©              0.0     0.0       0.0          0.0     25\n",
      "ë¹„êµ              0.0     0.0       0.0          0.0     25\n",
      "ìŠ¤í™              0.0     0.0       0.0          0.0     25\n",
      "ì¶”ì²œ              0.0     0.0       0.0          0.0     25\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ í‰ê°€ ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "evaluator.print_overall_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "t4pk7ouz5s8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n[í•µì‹¬ ì§€í‘œ ìš”ì•½]\n",
      "Total Queries: 100\n",
      "Micro F1 Score: 0.00%\n",
      "Macro F1 Score: 0.00%\n",
      "Exact Match Rate: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²´ í‰ê°€ ì§€í‘œ ë”•ì…”ë„ˆë¦¬ë¡œ ë°›ê¸°\n",
    "overall_metrics = evaluator.get_overall_metrics()\n",
    "\n",
    "print(\"\\\\n[í•µì‹¬ ì§€í‘œ ìš”ì•½]\")\n",
    "print(f\"Total Queries: {overall_metrics['total_queries']}\")\n",
    "print(f\"Micro F1 Score: {overall_metrics['micro_f1']:.2%}\")\n",
    "print(f\"Macro F1 Score: {overall_metrics['macro_f1']:.2%}\")\n",
    "print(f\"Exact Match Rate: {overall_metrics['exact_match_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qsksgk3sa1r",
   "metadata": {},
   "source": [
    "### 5. ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sr4hih6r1uo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "evaluator.save_results()  # ìë™ìœ¼ë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í¬í•¨ëœ íŒŒì¼ëª… ìƒì„±\n",
    "\n",
    "# ë˜ëŠ” ì›í•˜ëŠ” íŒŒì¼ëª…ìœ¼ë¡œ ì €ì¥\n",
    "# evaluator.save_results(\"my_evaluation_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6rqmdatx3q8",
   "metadata": {},
   "source": [
    "### 6. ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ (Text2SQL ëª¨ë¸ê³¼ í†µí•©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w2dkd1jr2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_text2sql_model(query_number: int, user_query: str):\n",
    "    \"\"\"\n",
    "    Text2SQL ëª¨ë¸ í‰ê°€ë¥¼ ìœ„í•œ ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "    \n",
    "    Args:\n",
    "        query_number: ì¿¼ë¦¬ ë²ˆí˜¸\n",
    "        user_query: ì‚¬ìš©ìì˜ ìì—°ì–´ ì¿¼ë¦¬\n",
    "    \n",
    "    Returns:\n",
    "        í‰ê°€ ê²°ê³¼\n",
    "    \"\"\"\n",
    "    # 1. Text2SQL ëª¨ë¸ë¡œ SQL ìƒì„± (ì—¬ê¸°ì— ì‹¤ì œ ëª¨ë¸ í˜¸ì¶œ ì½”ë“œ ì¶”ê°€)\n",
    "    # generated_sql = your_text2sql_model(user_query)\n",
    "    \n",
    "    # 2. ìƒì„±ëœ SQL ì‹¤í–‰í•˜ì—¬ product_id ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ (ì˜ˆì‹œ)\n",
    "    # predicted_product_ids = execute_sql_and_get_products(generated_sql)\n",
    "    \n",
    "    # ì˜ˆì‹œ ë°ì´í„° (ì‹¤ì œë¡œëŠ” ìœ„ì˜ ê³¼ì •ìœ¼ë¡œ ì–»ì€ ê²°ê³¼ ì‚¬ìš©)\n",
    "    predicted_product_ids = ['P001', 'P002', 'P003', 'P004']\n",
    "    \n",
    "    # 3. í‰ê°€ ì‹¤í–‰\n",
    "    result = evaluator.evaluate_single_query(query_number, predicted_product_ids)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "# result = evaluate_text2sql_model(1, \"ìµœê·¼ 3ê°œì›”ê°„ ê°€ì¥ ë§ì´ íŒ”ë¦° ìƒí’ˆì„ ì•Œë ¤ì£¼ì„¸ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4g9e0wh3vp7",
   "metadata": {},
   "source": [
    "### 7. ì—°ê²° ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c824e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rgd6bwe8eq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‘ì—… ì™„ë£Œ í›„ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ\n",
    "evaluator.close_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
